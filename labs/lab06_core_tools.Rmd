---
title: "Lab 6---Developing a set of core tools"
author: "Brooke Anderson"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
```

## Developing a set of core tools

In several parts of the lectures, we've discussed how useful it is to develop a
set of core tools in R that you know very well. Between base R and available R
packages, there are an enormous amount of tools that are available for R.
However, you'll often find that, for most of the tasks you perform, most of the
task can be done with a fairly small set of tools. If you identify this core set
and learn to use them very well, you'll find that you can code more efficiently
and that you are less likely to introduce or fail to fix bugs in your code.

The tidyverse tools are an excellent set of tools to learn as a core toolset.
Many of the tools are very similar to functions available in base R, but they
often are adjusted in small ways that make them more convenient for the average
user.

The tidyverse tools are divided into packages. A number of the packages are
focused on working with a type of data or data container. For example:

- `stringr`: Functions to work with character strings
- `lubridate`: Functions to work with dates
- `forcats`: Functions to work with factors
- `dplyr`: Functions to work with dataframes

Many of the tidyverse tools come out of a developer team at Posit (formerly
RStudio). However, other developers can also create and share packages that fit
within the tidyverse approach. One example is the `sf` package, which brings a
tidyverse approach to spatial data and is an extremely useful tool to learn if
you regularly create geospatial maps in R.

Once you have identified some tools that you want to include in your core
toolset, it is well worth your time to explore the tools deeply to make sure
that you understand how they work and are taking full advantage of them. In this
lab, we'll walk you through an approach to develop and learn more about a set of
tools available in the `stringr` package.

Also, this is the last lab of the workshop. Please feel free to also use this
lab time to complete any parts of earlier labs that you have not completed but
would like to, as well as talk to as about questions you have about applying the
material from the workshop in your own coding practice.

## Learning regular expression tools

The `stringr` package has excellent tools for leveraging regular expressions in
R. Regular expressions are an enormously powerful tool in R coding, especially
if you regularly work with messy data. They allow you to identify patterns in
character strings. You can then use information about those patterns to clean
your data, or combine them with logical statements to extract subsets of the
data.

We'll use this lab to explore some of the tools for regular expressions in the
`stringr` package. (The package also includes other tools for working with
character strings that do not involve regular expressions and in general is an
excellent package to add to your core toolset). In addition to teaching you some
of these functions (which you might already know), this lab aims to give you
some strategies for becoming more familiar with a tool you want to add to your
toolset. These strategies can apply more broadly as you build the set of tools
that you plan to use over and over in your coding.

As you work through the tasks of this lab, we'll ask you to reference some
materials that can help you learn the tools in `stringr`. These types of
resources are often available for R packages, and we recommend you get in the
habit of using them to improve your understanding of your tools. Use the
following resources as you work through the different tasks and figure out how
to solve them with functions from the `stringr` package:

- The `stringr` package cheatsheet: https://rstudio.github.io/cheatsheets/strings.pdf 
- Vignettes for `stringr`: Available through the "Articles" section of the pkgdown
site for the package: https://stringr.tidyverse.org/
- Tab completion and helpfiles for the package: at the console, type `?stringr::`, 
which will trigger tab completion to list all the functions in the package. When 
you find one that sounds promising, you can click on it to get the helpfile. Often, 
the examples at the end of the helpfile are a great place to start. 
- For tidyverse packages, there is often a helpful chapter in "R for Data Science". 
For `stringr`, the chapter is: https://r4ds.had.co.nz/strings.html 

## Set up data

We'll use the data from earlier labs. Let's start by running the code to set up 
this dataset. As a reminder, the code to do that is: 

```{r}
# Load required libraries ##############################################################
library(readr)
library(janitor)
library(dplyr)
library(lubridate)
library(tidyr)
library(purrr)
library(stringr)
library(ggplot2)

# Define functions ####################################################################

# To run this function, you will need to have the following functions installed:
# readr, janitor, dplyr, lubridate
read_and_clean_call_data <- function(file, remove_partial_years = FALSE){
  
  # Read in data and clean column names
  call_data <- readr::read_csv(file = file, id = "filename") %>% 
    janitor::clean_names() %>% 
    dplyr::rename(datetime_call = date_and_time_of_initial_call)
  
  # Limit to columns we'll need for our research question
  call_data <- call_data %>% 
    dplyr::select(datetime_call, property, location, species_description, 
                  animal_class, final_ranger_action, filename)
  
  call_data <- call_data %>% 
    # Convert date-time column to appropriate data type
    dplyr::mutate(datetime_call = lubridate::mdy_hms(datetime_call)) %>%
    # Add columns for the year and month of the call
    dplyr::mutate(call_year = lubridate::year(datetime_call),
                  call_month = lubridate::month(datetime_call,
                                                label = TRUE, 
                                                abbr = FALSE)) 
  
  if(remove_partial_years == TRUE) {
    call_data <- call_data %>% 
      dplyr::filter(call_year %in% c(2019, 2020))
  }
  
  return(call_data)
}

# Run analysis ########################################################################

# Create a vector with the names of all the files
borough_files <- list.files(path = "../data", full.names = TRUE)

# Read in data from all files, bind them together, and extract borough names from 
# the filenames
ny_calls <- borough_files %>% 
  map(.f = read_and_clean_call_data, remove_partial_years = TRUE) %>% 
  bind_rows() %>% 
  mutate(borough = filename, 
         borough = str_remove(borough, "../data/"), 
         borough = str_remove(borough, "_animal_response.csv"), 
         borough = str_replace(borough, "_", " "))
```

## Exploring and learning `stringr`

To show you how to learn more about some of the `stringr` regular expression
tools, we've set up a couple of tasks for you to try to do with the animal calls
data from earlier labs. These tasks are:

- Filter the data to certain types of animals. For example, filter to all animal 
response calls that involved snakes or alligators.
- Filter to all calls that came from a playground (may be listed in `property` 
or `location`)

If you look at the `ny_calls` dataset, you'll see that there are some columns in
it with information related to these tasks. These include the columns
`property`, `location`, `species_description`, and `animal_class`.

```{r}
ny_calls %>% 
  select(property, location, species_description, animal_class)
```

However, the information that we need to solve our tasks is often buried
somewhere in the values for those columns. For example, the `location` column
never says just "Playground", and the `species_description` never just says
"Snake". If they did, we could just filter with a statement that checks for an
exact match (e.g., with `==`). Instead, we'll need to figure out if certain
words are somewhere within the values given for those columns. Regular
expressions are a great tool to do this.

###  Filter the data to certain types of animals. 

Let's start with the first task, which is to see if you can filter the data to
certain types of animals. For example, see if you can filter the data to animal
response calls that involved snakes.

Start by taking a look at the data to see which column to search for this
information. There are two columns related to the type of animal in a call,
`species_description` and `animal_class`. From looking at the data, it looks
like `animal_class` gives broader descriptions of the type of animal ("Birds" or
"Small Mammals", for example). There's a value for "Terrestrial Reptile or
Amphibian", which would include snakes, but that will also include a lot of
other types of animals. It looks like what we'll need to search is instead
`species_description`, which gives the specific type of data (e.g., "Canada
Goose", "Racoon").

Let's see if there's a way to look for rows in the dataframe where the word
"snake" is included in the `species_description` column. We can start by looking
for rows where this column is exactly equal to the word "Snake" by using the
`filter` function from `dplyr` with a logical expression:

```{r}
ny_calls %>% 
  filter(species_description == "Snake")
```

This doesn't identify anything. This could mean that there aren't any calls with
snakes, but it could also mean that the snake listings include more details
about the species, so that the value in this column includes the word "snake" or
"Snake" but also includes some other words.

Next, we can look through the `stringr` cheatsheet
(https://rstudio.github.io/cheatsheets/strings.pdf) to see if there's anything
promising. We are looking for a function that can identify which values in
vector of character strings include a certain pattern, without that pattern
necessarily being the full value. Start by looking at the large categories on the
first page of the cheatsheet ("Detect Matches", "Subset Strings", and so on).
What we are trying to do here is to detect a string, so we can start looking in
that section.

There are five functions listed in the "Detect Matches" section: `str_detect`,
`str_starts`, `str_which`, `str_locate`, and `str_count`. If we read the
descriptions of these, two sound promising. The first is `str_detect`, which
detects if a match exists in each string in the vector, returning `TRUE` if it
does and `FALSE` otherwise. The second is `str_which`, which returns the indexes
of the strings in a vector that have a match.

Let's try out the examples for these two functions to see which would be a
better fit for the task we're trying to do. Let's start with the help file of
`str_detect`. You can pull that up in your R session by running:

```{r eval = FALSE}
?str_detect
```

Scroll down to the Examples section. It starts with the following code: 

```{r}
fruit <- c("apple", "banana", "pear", "pineapple")
str_detect(fruit, "a")
```

In this first example, the `str_detect` has looked for strings in the vector
that include the letter "a". All four values include an "a", so it returns a
vector where each value is `TRUE`.

One of the later examples is: 

```{r}
str_detect(fruit, "b")
```

In this case, the call is looking for values that include a "b" in the string.
In this case the second value ("banana") in the `fruit` string includes a "b",
but none of the other values do, so the vector that's returned has `TRUE` for
its second value and `FALSE` for all the others.

The other examples use more complex regular expression patterns. We'll get to
those ideas later, but for now, we're trying to match a straightforward pattern
(either "Snake" or "snake"), so we'll save the more complex patterns for later.

Next, let's look at the helpfile for `str_which`. Again, you can find that with: 

```{r eval = FALSE}
?str_which
```

Here is the first example in that helpfile: 

```{r}
fruit <- c("apple", "banana", "pear", "pineapple")
str_which(fruit, "a")
```

In this case, the function again is finding which strings include an "a".
However, instead of returning a vector with `TRUE` / `FALSE` for whether each
value includes an "a", it returns a number. Based on the Description at the top
of this help file, this lists the positions of the values that have a match. In
other words, the result in the example is saying that the values in the `fruit`
string with an "a" in them are the first, second, third, and fourth values.

If we've understood correctly, then if we run `str_which(fruit, "b")`, the
result should be just `2`, since only the second value in the `fruit` string
("banana") includes a "b". Let's try that out and see if we've understood:

```{r}
str_which(fruit, "b")
```

Now that we understand the two functions, we can decide which would work better.
As a reminder, our aim in this task is to take a dataframe and reduce it to only
the rows that include "Snake" or "snake" in its value for the
`species_description` column. When you want to pull out certain rows from a
dataframe, the `filter` function from the `dplyr` package is often a good way to
do that. In fact, this is what we tried earlier, when we looked for exact
matches of that column with the string "Snake". The `filter` function works
based on a logical statement---it will check some logical expression and keep
each row where the logic evaluates to `TRUE` and remove the ones where it
evaluates to `FALSE`. Based on this understanding of `filter`, we probably want
to use `str_detect`, since it returns `TRUE` / `FALSE` values, which `filter`
needs to do its part.

Let's try that out. We'll start by looking for rows where the string "Snake" is
included in `species_description`:

```{r}
ny_snake_calls <- ny_calls %>% 
  filter(str_detect(species_description, pattern = "Snake"))

ny_snake_calls
```

That seems to have worked well. However, it could miss a listing where the word
"snake" is in lowercase. There are several ways we could handle that. One way is
to create a more complex regular expression pattern to include in `str_detect`.
Essentially, we want to look for two patterns, either "Snake" or "snake".
Another way we can express this is that we want to look for either "S" or "s"
followed by "nake".

The second page of the `stringr` cheatsheet provides help on specifying regular
expression patterns. Again, this page is divided into sections and subsections.
In the "Regular Expressions" section, one of the subsections is "Alternates".
That's where we're interested in here---a pattern where at one spot (the first
letter) the pattern could have one of two letters ("S" or "s"---regular
expressions are case-sensitive). Based on this subsection, if we want to express
that a pattern could include "one of" several values, we should use square
brackets to express that in the pattern.

The cheatsheet includes examples in this subsection, to help us see how the
patterns work. It sets up all the examples by defining a function:

```{r}
alt <- function(rx) str_view("abcde", rx)
```

If we look at this, we can see that it's defining a function that will run
`str_view` on the string "abcde", with the pattern that we input using the
parameter `rx`. If we look on the first page of the cheatsheet, we can see what
the `str_view` function does. It's listed in the "Helpers" section, which says
it will give an HTML rendering of the matches. Let's try just that function with
a simple example, using the string "abcde" and matching to the pattern "a":

```{r}
str_view("abcde", pattern = "a")
```

You can see that this uses formatting to show the part of the string that's a
match. It looks like this is a function that we can use to test out different
patterns to see if they're matching what we want. Let's try it with an example
relevant to our task:

```{r}
snake_examples <- c("Snake", "snake", "Snake (Unknown)", "Garter Snake", 
                    "Chicken", "Squirrel")
str_view(snake_examples, pattern = "Snake")
```

We can see that the pattern "Snake" identifies all the examples we want except
the one in lowercase ("snake") and excludes the values we don't want ("Chicken"
and "Squirrel").

Next, we can try the example for using the "one of" alternate pattern with
square brackets from the cheatsheet:

```{r}
alt <- function(rx) str_view("abcde", rx)
alt("[abe]") 
```

We can see that the square brackets let us pick out any one of the letters a, b,
and e in these examples. Let's try it with our example. First, in the
`snake_examples`, let's see if we can pick out every "s", regardless of if it's
uppercase or lowercase:

```{r}
str_view(snake_examples, pattern = "[sS]")
```

Now we are getting the lowercase value ("snake"), but it's a little too
inclusive because we're picking up a value we don't want ("Squirrel"). Let's try
expanding our pattern so it captures a string that starts with "S" or "s" and
then ends with "nake":

```{r}
str_view(snake_examples, pattern = "[sS]nake")
```

This gets exactly what we want. Let's update our filtering call with the full
dataset to use this pattern:

```{r}
ny_snake_calls <- ny_calls %>% 
  filter(str_detect(species_description, pattern = "[sS]nake"))

ny_snake_calls
```

This pattern works in our call. In this case, it looks like "Snake" is always
capitalized in `species_description`, so our results haven't changed. However,
often our data won't be that clean.

For example, one of our other tasks is to find calls that came from playgrounds.
If we explore the data some, we see that sometimes playgrounds are listed as the
`property` that the call came from. In other cases, the call might come from a
bigger property (e.g., "Central Park"), with the playground listed in
`location`. It looks like the values in the `location` column aren't as clean
and consistent as the ones in the `species_description` column, so there's a
good chance that we need to look for both "Playground" and "playground".

Let's look for examples of these listings in both columns. As we're exploring,
we can use the `pull` function from `dplyr` as a way to pull out one column of a
dataframe as a vector and work with it alone.

```{r}
ny_calls %>% 
  pull(property) %>% 
  str_view(pattern = "[Pp]layground")
```

```{r}
ny_calls %>% 
  pull(location) %>% 
  str_view(pattern = "[Pp]layground")
```

It looks like the `property` column is consistent in always using "Playground",
but the `location` column is not, and therefore it's important that we look for
both "Playground" and "playground".

Now that we have the patterns we want to use, we can use them along with
`filter` to get animal response calls that came from playgrounds:

```{r}
playground_animal_calls <- ny_calls %>% 
  filter(str_detect(property, pattern = "Playground") | 
           str_detect(location, pattern = "[pP]layground"))
playground_animal_calls
```

## Continuing to explore regular expressions

In these tasks, we've dug into how one tool in `stringr` works with regular
expressions, and this process can help us add `str_detect` to our core set of
tools. If you work with character strings a lot---particularly in the context of
cleaning messy data---you may want to continue to explore other `stringr`
functions.

Here are two other tasks you could try to build up that toolset: 

- Find all calls where the `location` column seems to include a latitude and 
longitude. Extract these values into separate columns for the latitude and
longitude, with each as a numeric variable. As a hint, you'll be looking for
values in the `location` column that include a pattern like "40.869531,
-73.785360". This task will take a lot of work with the `stringr` cheatsheet and
other resources if you haven't done a task like this before, but is a very
powerful tool to have available.
- Identify all rows where the `location` column is listed as `"N/A"`, `"N/a"`, 
`"n/A"`, or `"n/a"`. Convert these values to the "NA" that R recognizes as a
missing value.

# Session info

Here is information about the session under which the lab document was 
run: 

```{r eval = TRUE}
sessionInfo()
```
